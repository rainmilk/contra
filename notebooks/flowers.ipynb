{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-01-04T06:10:42.562244Z","iopub.status.busy":"2022-01-04T06:10:42.561893Z","iopub.status.idle":"2022-01-04T06:10:44.993941Z","shell.execute_reply":"2022-01-04T06:10:44.993208Z","shell.execute_reply.started":"2022-01-04T06:10:42.562172Z"},"trusted":true},"outputs":[],"source":["import glob\n","from itertools import chain\n","import os\n","import random\n","import zipfile\n","from tqdm.notebook import tqdm\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets, transforms, models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_dir = \"../data/flowers-102\"\n","train_dir = data_dir + \"/train\"\n","valid_dir = data_dir + \"/valid\"\n","test_dir = data_dir + \"/test\"\n","\n","\n","# Define transforms for the training data and testing data\n","train_transforms = transforms.Compose(\n","    [\n","        transforms.RandomRotation(30),\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","    ]\n",")\n","\n","valid_transforms = transforms.Compose(\n","    [\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","    ]\n",")\n","\n","test_transforms = transforms.Compose(\n","    [\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n","    ]\n",")\n","\n","\n","# Pass transforms in here, then run the next cell to see how the transforms look\n","train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n","valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n","test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n","\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=True)\n","validloader = torch.utils.data.DataLoader(valid_data, batch_size=50)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T06:10:44.996172Z","iopub.status.busy":"2022-01-04T06:10:44.995898Z","iopub.status.idle":"2022-01-04T06:10:44.999997Z","shell.execute_reply":"2022-01-04T06:10:44.999055Z","shell.execute_reply.started":"2022-01-04T06:10:44.996137Z"},"trusted":true},"outputs":[],"source":["PATH_TRAIN = \"../input/pytorch-challange-flower-dataset/dataset/train\"\n","PATH_VALID = \"../input/pytorch-challange-flower-dataset/dataset/valid\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T06:10:45.002113Z","iopub.status.busy":"2022-01-04T06:10:45.001549Z","iopub.status.idle":"2022-01-04T06:10:45.020088Z","shell.execute_reply":"2022-01-04T06:10:45.019174Z","shell.execute_reply.started":"2022-01-04T06:10:45.002077Z"},"trusted":true},"outputs":[],"source":["class TripletData(Dataset):\n","    def __init__(self, path, transforms, split=\"train\"):\n","        self.path = path\n","        self.split = split  # train or valid\n","        self.cats = 102  # number of categories\n","        self.transforms = transforms\n","\n","    def __getitem__(self, idx):\n","        # our positive class for the triplet\n","        idx = str(idx % self.cats + 1)\n","\n","        # choosing our pair of positive images (im1, im2)\n","        positives = os.listdir(os.path.join(self.path, idx))\n","        im1, im2 = random.sample(positives, 2)\n","\n","        # choosing a negative class and negative image (im3)\n","        negative_cats = [str(x + 1) for x in range(self.cats)]\n","        negative_cats.remove(idx)\n","        negative_cat = str(random.choice(negative_cats))\n","        negatives = os.listdir(os.path.join(self.path, negative_cat))\n","        im3 = random.choice(negatives)\n","\n","        im1, im2, im3 = (\n","            os.path.join(self.path, idx, im1),\n","            os.path.join(self.path, idx, im2),\n","            os.path.join(self.path, negative_cat, im3),\n","        )\n","\n","        im1 = self.transforms(Image.open(im1))\n","        im2 = self.transforms(Image.open(im2))\n","        im3 = self.transforms(Image.open(im3))\n","\n","        return [im1, im2, im3]\n","\n","    # we'll put some value that we want since there can be far too many triplets possible\n","    # multiples of the number of images/ number of categories is a good choice\n","    def __len__(self):\n","        return self.cats * 8\n","\n","\n","# Transforms\n","train_transforms = transforms.Compose(\n","    [\n","        transforms.Resize((224, 224)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ]\n",")\n","\n","val_transforms = transforms.Compose(\n","    [\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ]\n",")\n","\n","\n","# Datasets and Dataloaders\n","train_data = TripletData(PATH_TRAIN, train_transforms)\n","val_data = TripletData(PATH_VALID, val_transforms)\n","\n","train_loader = torch.utils.data.DataLoader(\n","    dataset=train_data, batch_size=32, shuffle=True, num_workers=4\n",")\n","val_loader = torch.utils.data.DataLoader(\n","    dataset=val_data, batch_size=32, shuffle=False, num_workers=4\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T06:10:45.029926Z","iopub.status.busy":"2022-01-04T06:10:45.029519Z","iopub.status.idle":"2022-01-04T06:10:45.037461Z","shell.execute_reply":"2022-01-04T06:10:45.036701Z","shell.execute_reply.started":"2022-01-04T06:10:45.029891Z"},"trusted":true},"outputs":[],"source":["class TripletLoss(nn.Module):\n","    def __init__(self, margin=1.0):\n","        super(TripletLoss, self).__init__()\n","        self.margin = margin\n","\n","    def calc_euclidean(self, x1, x2):\n","        return (x1 - x2).pow(2).sum(1)\n","\n","    # Distances in embedding space is calculated in euclidean\n","    def forward(self, anchor, positive, negative):\n","        distance_positive = self.calc_euclidean(anchor, positive)\n","        distance_negative = self.calc_euclidean(anchor, negative)\n","        losses = torch.relu(distance_positive - distance_negative + self.margin)\n","        return losses.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T06:42:13.812895Z","iopub.status.busy":"2022-01-04T06:42:13.81264Z","iopub.status.idle":"2022-01-04T06:42:50.522759Z","shell.execute_reply":"2022-01-04T06:42:50.521914Z","shell.execute_reply.started":"2022-01-04T06:42:13.812867Z"},"trusted":true},"outputs":[],"source":["epochs = 2\n","device = \"cuda\"\n","\n","# Our base model\n","model = models.resnet18().cuda()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","triplet_loss = TripletLoss()\n","\n","# Training\n","for epoch in range(epochs):\n","\n","    model.train()\n","    epoch_loss = 0.0\n","    for data in tqdm(train_loader):\n","        optimizer.zero_grad()\n","        x1, x2, x3 = data\n","        e1 = model(x1.to(device))\n","        e2 = model(x2.to(device))\n","        e3 = model(x3.to(device))\n","\n","        loss = triplet_loss(e1, e2, e3)\n","        epoch_loss += loss\n","        loss.backward()\n","        optimizer.step()\n","    print(\"Train Loss: {}\".format(epoch_loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install faiss-gpu"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#!pip install faiss-gpu\n","import faiss\n","\n","faiss_index = faiss.IndexFlatL2(1000)  # build the index\n","\n","im_indices = []\n","with torch.no_grad():\n","    for f in glob.glob(os.path.join(PATH_TRAIN, \"*/*\")):\n","        im = Image.open(f)\n","        im = im.resize((224, 224))\n","        im = torch.tensor([val_transforms(im).numpy()]).cuda()\n","\n","        preds = model(im)\n","        preds = np.array([preds[0].cpu().numpy()])\n","        faiss_index.add(preds)  # add the representation to index\n","        im_indices.append(f)  # store the image name to find it later on"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-04T06:27:21.4972Z","iopub.status.busy":"2022-01-04T06:27:21.496642Z","iopub.status.idle":"2022-01-04T06:27:21.501164Z","shell.execute_reply":"2022-01-04T06:27:21.499905Z","shell.execute_reply.started":"2022-01-04T06:27:21.497163Z"},"trusted":true},"outputs":[],"source":["PATH_TEST = \"../input/pytorch-challange-flower-dataset/dataset/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    for f in os.listdir(PATH_TEST):\n","        im = Image.open(os.path.join(PATH_TEST, f))\n","        im = im.resize((224, 224))\n","        im = torch.tensor([val_transforms(im).numpy()]).cuda()\n","\n","        test_embed = model(im).cpu().numpy()\n","        _, I = faiss_index.search(test_embed, 5)\n","        print(\"Retrieved Image: {}\".format(im_indices[I[0][0]]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":336091,"sourceId":668380,"sourceType":"datasetVersion"},{"datasetId":76785,"sourceId":2271054,"sourceType":"datasetVersion"}],"dockerImageVersionId":30153,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":4}
