{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from configs import settings\n",
    "from core_model.custom_model import ClassifierWrapper, load_custom_model\n",
    "from core_model.dataset import get_dataset_loader\n",
    "from core_model.train_test import model_forward\n",
    "\n",
    "set_noise_ratio='0.5'\n",
    "set_noise_type='asymmetric'\n",
    "set_uni_name='Coteaching,Coteachingplus,Decoupling'\n",
    "set_dataset='cifar-10'\n",
    "set_model='cifar-resnet18'\n",
    "set_model_suffix='restore'\n",
    "set_batch_size=64\n",
    "\n",
    "\n",
    "\n",
    "def execute():\n",
    "    case = settings.get_case(set_noise_ratio,set_noise_type)\n",
    "    print('得到的case',case)\n",
    "    uni_names = set_uni_name\n",
    "    uni_names = [uni_names] if uni_names is None else uni_names.split(\",\")\n",
    "    num_classes = settings.num_classes_dict[set_dataset]\n",
    "\n",
    "    loaded_model = load_custom_model(set_model, num_classes, load_pretrained=False)\n",
    "    model = ClassifierWrapper(loaded_model, num_classes)\n",
    "\n",
    "    _, _, test_loader = get_dataset_loader(\n",
    "        set_dataset,\n",
    "        \"test\",\n",
    "        None,\n",
    "        batch_size=set_batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    _, _, noisy_loader = get_dataset_loader(\n",
    "        set_dataset,\n",
    "        \"train_noisy\",\n",
    "        case,\n",
    "        batch_size=set_batch_size,\n",
    "        shuffle=False,\n",
    "        label_name=\"train_noisy_true_label\"\n",
    "    )\n",
    "    \n",
    "    results_data=[]\n",
    "\n",
    "    for uni_name in uni_names:\n",
    "        print(f\"Evaluating {uni_name}:\")\n",
    "        model_ckpt_path = settings.get_ckpt_path(\n",
    "            set_dataset,\n",
    "            case,\n",
    "            set_model,\n",
    "            model_suffix=set_model_suffix,\n",
    "            unique_name=uni_name,\n",
    "        )\n",
    "        print(f\"Loading model from {model_ckpt_path}\")\n",
    "        checkpoint = torch.load(model_ckpt_path)\n",
    "        model.load_state_dict(checkpoint, strict=False)\n",
    "        # print(f\"Evaluating test_data:\")\n",
    "        # results, embedding = model_test(test_loader, model)\n",
    "        # print(\"Results: %.4f\" % results)\n",
    "        print(f\"Evaluating train_noisy_data:\")\n",
    "        n_results, n_embedding = model_test(noisy_loader, model)\n",
    "        # print(\"Results: %.4f\" % results)\n",
    "        print(\"Results: \", n_results)\n",
    "        dict_temp={'uni_name':uni_name,**n_results}\n",
    "        results_data.append(dict_temp)\n",
    "    \n",
    "    df=pd.DataFrame(results_data)\n",
    "    return df        \n",
    "\n",
    "\n",
    "\n",
    "def model_test(data_loader, model, device=\"cuda\"):\n",
    "    eval_results = {}\n",
    "\n",
    "    predicts, probs, embedding, labels = model_forward(\n",
    "        data_loader, model, device, output_embedding=True, output_targets=True\n",
    "    )\n",
    "\n",
    "    # global acc\n",
    "    global_acc = np.mean(predicts == labels)\n",
    "    eval_results[\"global\"] = global_acc.item()\n",
    "\n",
    "    # class acc\n",
    "    label_list = sorted(list(set(labels)))\n",
    "    for label in label_list:\n",
    "        cls_index = labels == label\n",
    "        class_acc = np.mean(predicts[cls_index] == labels[cls_index])\n",
    "        eval_results[\"label_\" + str(label.item())] = class_acc.item()\n",
    "\n",
    "    return eval_results, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得到的case nr_0.5_nt_asymmetric_cvpr\n",
      "Loading /nvme/szh/code/tta-mr/data/cifar-10/gen/test_data.npy\n",
      "Loading /nvme/szh/code/tta-mr/data/cifar-10/gen/nr_0.5_nt_asymmetric_cvpr/train_noisy_data.npy\n",
      "Evaluating Coteaching:\n",
      "Loading model from /nvme/szh/code/tta-mr/ckpt/cifar-10/nr_0.5_nt_asymmetric_cvpr/Coteaching/cifar-resnet18_restore.pth\n",
      "Evaluating train_noisy_data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-bbcf77932c39>:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_ckpt_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  {'global': 0.93824, 'label_0': 0.8938906752411575, 'label_1': 0.9897476340694006, 'label_2': 0.865979381443299, 'label_3': 0.8432304038004751, 'label_4': 0.988198269079465, 'label_5': 0.9153526970954357, 'label_6': 0.9829406986190089, 'label_7': 0.9629331184528606, 'label_8': 0.9850393700787402, 'label_9': 0.9542536115569823}\n",
      "Evaluating Coteachingplus:\n",
      "Loading model from /nvme/szh/code/tta-mr/ckpt/cifar-10/nr_0.5_nt_asymmetric_cvpr/Coteachingplus/cifar-resnet18_restore.pth\n",
      "Evaluating train_noisy_data:\n",
      "Results:  {'global': 0.94696, 'label_0': 0.9646302250803859, 'label_1': 0.9503154574132492, 'label_2': 0.9191118160190325, 'label_3': 0.9517022961203484, 'label_4': 0.970889063729347, 'label_5': 0.9651452282157676, 'label_6': 0.9593826157595451, 'label_7': 0.8944399677679291, 'label_8': 0.931496062992126, 'label_9': 0.9630818619582665}\n",
      "Evaluating Decoupling:\n",
      "Loading model from /nvme/szh/code/tta-mr/ckpt/cifar-10/nr_0.5_nt_asymmetric_cvpr/Decoupling/cifar-resnet18_restore.pth\n",
      "Evaluating train_noisy_data:\n",
      "Results:  {'global': 0.9584, 'label_0': 0.9702572347266881, 'label_1': 0.9566246056782335, 'label_2': 0.9310071371927042, 'label_3': 0.9635787806809184, 'label_4': 0.9866247049567269, 'label_5': 0.9775933609958506, 'label_6': 0.9707554833468724, 'label_7': 0.9121676067687349, 'label_8': 0.9393700787401574, 'label_9': 0.9767255216693419}\n"
     ]
    }
   ],
   "source": [
    "#把所有模型的结果存到一个dataframe 里面\n",
    "results=pd.DataFrame()\n",
    "results=execute()\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uni_name</th>\n",
       "      <th>global</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coteaching</td>\n",
       "      <td>0.93824</td>\n",
       "      <td>0.893891</td>\n",
       "      <td>0.989748</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>0.843230</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.915353</td>\n",
       "      <td>0.982941</td>\n",
       "      <td>0.962933</td>\n",
       "      <td>0.985039</td>\n",
       "      <td>0.954254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coteachingplus</td>\n",
       "      <td>0.94696</td>\n",
       "      <td>0.964630</td>\n",
       "      <td>0.950315</td>\n",
       "      <td>0.919112</td>\n",
       "      <td>0.951702</td>\n",
       "      <td>0.970889</td>\n",
       "      <td>0.965145</td>\n",
       "      <td>0.959383</td>\n",
       "      <td>0.894440</td>\n",
       "      <td>0.931496</td>\n",
       "      <td>0.963082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decoupling</td>\n",
       "      <td>0.95840</td>\n",
       "      <td>0.970257</td>\n",
       "      <td>0.956625</td>\n",
       "      <td>0.931007</td>\n",
       "      <td>0.963579</td>\n",
       "      <td>0.986625</td>\n",
       "      <td>0.977593</td>\n",
       "      <td>0.970755</td>\n",
       "      <td>0.912168</td>\n",
       "      <td>0.939370</td>\n",
       "      <td>0.976726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uni_name   global   label_0   label_1   label_2   label_3   label_4  \\\n",
       "0      Coteaching  0.93824  0.893891  0.989748  0.865979  0.843230  0.988198   \n",
       "1  Coteachingplus  0.94696  0.964630  0.950315  0.919112  0.951702  0.970889   \n",
       "2      Decoupling  0.95840  0.970257  0.956625  0.931007  0.963579  0.986625   \n",
       "\n",
       "    label_5   label_6   label_7   label_8   label_9  \n",
       "0  0.915353  0.982941  0.962933  0.985039  0.954254  \n",
       "1  0.965145  0.959383  0.894440  0.931496  0.963082  \n",
       "2  0.977593  0.970755  0.912168  0.939370  0.976726  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #柱状图\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.font_manager as fm\n",
    "# from math import pi\n",
    "# import numpy as np\n",
    "\n",
    "# # Defining method categories\n",
    "# lnl_methods = ['Coteaching', 'Coteachingplus', 'Decoupling', 'NegativeLearning', 'PENCIL']\n",
    "# unlearning_methods = ['raw', 'GA', 'FT', 'FT_l1', 'FT_prune', 'retrain', 'retrain_ls', 'retrain_sam']\n",
    "\n",
    "# baseline_methods = ['pretrain', 'inc_train'] \n",
    "\n",
    "# datasets = ['cifar-10_sym', 'cifar-100_asym', 'flower-102_sym', 'pet-37_asym']\n",
    "# display_name_dataset = {\n",
    "#     'cifar-10_sym' : 'Cifar-10', \n",
    "#     'cifar-100_asym': 'Cifar-100', \n",
    "#     'flower-102_sym': 'Flower-102', \n",
    "#     'pet-37_asym' : 'Oxford-IIIT Pet'\n",
    "# }\n",
    "\n",
    "# display_name_legend = {\n",
    "#     'pretrain' : 'PreTrain', \n",
    "#     'inc_train' : 'IncTrain', \n",
    "#     'finetune': 'FineTune', \n",
    "#     'Coteaching' : 'CoTe.', \n",
    "#     'Coteachingplus': 'CoTe.+', \n",
    "#     'Decoupling': 'Decoup.', \n",
    "#     'NegativeLearning' : 'NegLn.', \n",
    "#     'PENCIL' : 'PENCIL', \n",
    "#     'raw': 'Raw', \n",
    "#     'GA': 'GA', \n",
    "#     'FT': 'FT', \n",
    "#     'FT_l1': 'FT-$l_{1}$', \n",
    "#     'FT_prune' : 'FT$_p$', \n",
    "#     'retrain' : 'ReT', \n",
    "#     'retrain_ls' : 'ReT$_L$', \n",
    "#     'retrain_sam' : 'ReT$_S$', \n",
    "#     'CRUL' : 'CRUL'\n",
    "# }\n",
    "\n",
    "# # Creating a bar chart to compare accuracy across methods for each dataset\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "# axes = axes.flatten()\n",
    "# width = 0.7  # Increased the width of the bars for better visibility\n",
    "# tfs = 12 # x/y-ticks font size\n",
    "# title_size = 18 # Title font size\n",
    "# lfs = 14 # Legend-font-size\n",
    "\n",
    "# # Colors for different categories\n",
    "# baseline_colors = ['lightgrey', 'darkgrey', 'silver']\n",
    "# lnl_colors = plt.cm.Blues(np.linspace(0.4, 1, 5))\n",
    "# unlearning_colors = plt.cm.Greens(np.linspace(0.4, 1, 8))\n",
    "# crul_color = 'red'\n",
    "\n",
    "\n",
    "# # Plotting each dataset in a separate subplot\n",
    "# for idx, dataset in enumerate(datasets):\n",
    "#     ax = axes[idx]\n",
    "#     x = np.arange(len(baseline_methods) + len(lnl_methods) + len(unlearning_methods) + 1)  # the label locations\n",
    "    \n",
    "#     # Plotting baseline methods (pretrain, noise-train, finetune)\n",
    "#     for i, method in enumerate(baseline_methods):\n",
    "#         ax.bar(x[i], sheet1_df.loc[dataset, method], width, label=method, color=baseline_colors[i], edgecolor='black', hatch=['//', '..'][i]) # 仅保留 pretrain和inc_train\n",
    "\n",
    "#     # Plotting LNL methods\n",
    "#     for i, method in enumerate(lnl_methods):\n",
    "#         ax.bar(x[len(baseline_methods) + i], sheet1_df.loc[dataset, method], width, label=method, color=lnl_colors[i], edgecolor='black')\n",
    "\n",
    "#     # Plotting Unlearning methods\n",
    "#     for i, method in enumerate(unlearning_methods):\n",
    "#         ax.bar(x[len(baseline_methods) + len(lnl_methods) + i], sheet1_df.loc[dataset, method], width, label=method, color=unlearning_colors[i], edgecolor='black')\n",
    "\n",
    "#     ax.bar(x[-1], sheet1_df.loc[dataset, 'CRUL'], width, label='CRUL', color=crul_color, edgecolor='black')\n",
    "\n",
    "#     ax.set_title(f'{display_name_dataset[dataset]}', fontsize=title_size, fontfamily=\"serif\", weight=\"bold\")\n",
    "\n",
    "#     ax.set_xticks([]) # 关闭x轴显示\n",
    "\n",
    "\n",
    "# # --------------------------------------------------------------------------------- #\n",
    "# \"\"\"\n",
    "# 手动修正四个子图各自的坐标值范围。\n",
    "# # \"\"\"\n",
    "# # # Cifar-10\n",
    "# axes[0].set_ylim(40, 85)\n",
    "# axes[0].set_yticks(np.arange(40, 91, 15))\n",
    "# axes[0].set_yticklabels(\n",
    "#             np.arange(40, 91, 15),\n",
    "#             fontsize=tfs,\n",
    "#             rotation=90,\n",
    "#             va=\"center\",\n",
    "#             fontfamily=\"serif\",\n",
    "#             weight=\"bold\",\n",
    "#         )\n",
    "\n",
    "\n",
    "# # Cifar-100\n",
    "# axes[1].set_ylim(50, 70)\n",
    "# axes[1].set_yticks(np.arange(50, 71, 5))\n",
    "# axes[1].set_yticklabels(\n",
    "#             np.arange(50, 71, 5),\n",
    "#             fontsize=tfs,\n",
    "#             rotation=90,\n",
    "#             va=\"center\",\n",
    "#             fontfamily=\"serif\",\n",
    "#             weight=\"bold\",\n",
    "#         )\n",
    "\n",
    "# # Flower-102\n",
    "# axes[2].set_ylim(50, 95)\n",
    "# axes[2].set_yticks(np.arange(50, 96, 15))\n",
    "# axes[2].set_yticklabels(\n",
    "#             np.arange(50, 96, 15),\n",
    "#             fontsize=tfs,\n",
    "#             rotation=90,\n",
    "#             va=\"center\",\n",
    "#             fontfamily=\"serif\",\n",
    "#             weight=\"bold\",\n",
    "#         )\n",
    "\n",
    "\n",
    "# # Pet-37\n",
    "# axes[3].set_ylim(70, 95)\n",
    "# axes[3].set_yticks(np.arange(70, 96, 10))\n",
    "# axes[3].set_yticklabels(\n",
    "#             np.arange(70, 96, 10),\n",
    "#             fontsize=tfs,\n",
    "#             rotation=90,\n",
    "#             va=\"center\",\n",
    "#             fontfamily=\"serif\",\n",
    "#             weight=\"bold\",\n",
    "#         )\n",
    "\n",
    "\n",
    "# handles, legend_labels = fig.axes[0].get_legend_handles_labels()\n",
    "\n",
    "# labels = [display_name_legend[ll] for ll in legend_labels]\n",
    "\n",
    "# legend_font_properties = fm.FontProperties(\n",
    "#                                         #    weight='bold', \n",
    "#                                            size=lfs)\n",
    "\n",
    "# from matplotlib.lines import Line2D\n",
    "# empty_handle = Line2D([], [], color='none')  # 创建一个空的占位符\n",
    "\n",
    "# # 在第二个 legend 之后插入占位符\n",
    "# handles.insert(2, empty_handle)\n",
    "# labels.insert(2, '')  # 对应的标签留空\n",
    "\n",
    "# fig.legend(handles, labels, loc='lower center', \n",
    "#            bbox_to_anchor=(0.5, -0.05), ncol=6,\n",
    "#            prop=legend_font_properties)\n",
    "\n",
    "# fig.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #雷达图\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from math import pi\n",
    "\n",
    "# # CIFAR-10的标签\n",
    "# labels = ['label0', 'label1', 'label2', 'label3', 'label4', 'label5', 'label6', 'label7', 'label8', 'label9']\n",
    "\n",
    "# # 假设数据\n",
    "# our_method_scores = [0.85, 0.88, 0.82, 0.80, 0.83, 0.87, 0.84, 0.86, 0.81, 0.89]\n",
    "# resnet18_scores = [0.75, 0.77, 0.74, 0.70, 0.73, 0.78, 0.76, 0.75, 0.72, 0.74]\n",
    "\n",
    "# # 设置雷达图的角度\n",
    "# num_vars = len(labels)\n",
    "\n",
    "# # 角度计算（每个标签对应一个角度）\n",
    "# angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "\n",
    "# # 将数据循环到开始位置，这样雷达图会闭合\n",
    "# our_method_scores += our_method_scores[:1]\n",
    "# resnet18_scores += resnet18_scores[:1]\n",
    "# angles += angles[:1]\n",
    "\n",
    "# # 创建雷达图\n",
    "# fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "\n",
    "# # 画 Our method 和 ResNet18 的雷达图\n",
    "# ax.plot(angles, our_method_scores, color='blue', linewidth=2, label='Our method')\n",
    "# ax.fill(angles, our_method_scores, color='blue', alpha=0.25)\n",
    "\n",
    "# ax.plot(angles, resnet18_scores, color='red', linewidth=2, label='ResNet18')\n",
    "# ax.fill(angles, resnet18_scores, color='red', alpha=0.25)\n",
    "\n",
    "# # 设置标签（CIFAR-10的类别）\n",
    "# ax.set_yticklabels([])\n",
    "# ax.set_xticks(angles[:-1])\n",
    "# ax.set_xticklabels(labels, fontsize=10)\n",
    "\n",
    "# # 添加标题\n",
    "# ax.set_title('Comparison of Our method and ResNet18 on CIFAR-10', size=14, color='black', y=1.1)\n",
    "\n",
    "# # 添加图例\n",
    "# ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.05))\n",
    "\n",
    "# # 显示图形\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 方法名和对应的准确率（根据实际结果替换这些数据）\n",
    "# methods = ['Our method', 'ResNet18', 'Method A', 'Method B']\n",
    "# accuracies = [0.85, 0.75, 0.78, 0.80] # 假设这四种方法在 CIFAR-10 上的准确率\n",
    "\n",
    "# # 设置柱状图的宽度和位置\n",
    "# x = np.arange(len(methods)) # 方法的数量\n",
    "# width = 0.5 # 每个柱子的宽度\n",
    "\n",
    "# # 创建柱状图\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# # 绘制柱状图\n",
    "# bars = ax.bar(x, accuracies, width, color=['blue', 'red', 'green', 'orange'])\n",
    "\n",
    "# # 设置标签和标题\n",
    "# ax.set_xlabel('Methods', fontsize=12)\n",
    "# ax.set_ylabel('Accuracy', fontsize=12)\n",
    "# ax.set_title('Comparison of Different Methods on CIFAR-10', fontsize=14)\n",
    "# ax.set_xticks(x) # 设置 X 轴刻度位置\n",
    "# ax.set_xticklabels(methods, fontsize=12) # 设置 X 轴标签\n",
    "\n",
    "# # 添加柱状图的数值标签\n",
    "# for bar in bars:\n",
    "#     height = bar.get_height()\n",
    "#     ax.annotate(f'{height:.2f}', # 显示每个柱的准确率\n",
    "#     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "#     xytext=(0, 3), # 偏移量\n",
    "#     textcoords=\"offset points\",\n",
    "#     ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# # 显示图形\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
